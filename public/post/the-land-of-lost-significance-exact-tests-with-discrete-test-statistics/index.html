<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>Practically Insignificant  | Quantum Statistics: Exact Tests with Discrete Test Statistics</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="generator" content="Hugo 0.62.0" />
    
    
      <META NAME="ROBOTS" CONTENT="NOINDEX, NOFOLLOW">
    

    
    
      <link href="/dist/css/app.d98f2eb6bcd1eaedb7edf166bd16af26.css" rel="stylesheet">
    

    

    
      
    

    
    
    <meta property="og:title" content="Quantum Statistics: Exact Tests with Discrete Test Statistics" />
<meta property="og:description" content="For those who ended up here looking for information about quantum statistical mechanics or particle statistics: apologies! But sometimes I feel like physicists took all the exciting names, so I’m stealing the term quanta as it relates to an observable that can take on only discrete (not continuous values). That has interesting consequences for inferential procedures based on such discrete (“quantum”) statistics, as we will see in this post." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/post/the-land-of-lost-significance-exact-tests-with-discrete-test-statistics/" />
<meta property="article:published_time" content="2020-06-28T00:00:00+00:00" />
<meta property="article:modified_time" content="2020-06-28T00:00:00+00:00" />
<meta itemprop="name" content="Quantum Statistics: Exact Tests with Discrete Test Statistics">
<meta itemprop="description" content="For those who ended up here looking for information about quantum statistical mechanics or particle statistics: apologies! But sometimes I feel like physicists took all the exciting names, so I’m stealing the term quanta as it relates to an observable that can take on only discrete (not continuous values). That has interesting consequences for inferential procedures based on such discrete (“quantum”) statistics, as we will see in this post.">
<meta itemprop="datePublished" content="2020-06-28T00:00:00&#43;00:00" />
<meta itemprop="dateModified" content="2020-06-28T00:00:00&#43;00:00" />
<meta itemprop="wordCount" content="1257">



<meta itemprop="keywords" content="statistics," /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Quantum Statistics: Exact Tests with Discrete Test Statistics"/>
<meta name="twitter:description" content="For those who ended up here looking for information about quantum statistical mechanics or particle statistics: apologies! But sometimes I feel like physicists took all the exciting names, so I’m stealing the term quanta as it relates to an observable that can take on only discrete (not continuous values). That has interesting consequences for inferential procedures based on such discrete (“quantum”) statistics, as we will see in this post."/>

  </head>

  <body class="ma0 avenir bg-near-white">

    
   
  

  <header>
    <div class="bg-black">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="/" class="f3 fw2 hover-white no-underline white-90 dib">
      Practically Insignificant
    </a>
    <div class="flex-l items-center">
      

      
      












    </div>
  </div>
</nav>

    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3">

    <header class="mt4 w-100">
      <p class="f6 b helvetica tracked">
          
        POSTS
      </p>
      <h1 class="f1 athelas mb1">Quantum Statistics: Exact Tests with Discrete Test Statistics</h1>
      
      
      <time class="f6 mv4 dib tracked" datetime="2020-06-28T00:00:00Z">June 28, 2020</time>
      
      
    </header>

    <section class="nested-copy-line-height lh-copy serif f4 nested-links nested-img mid-gray pr4-l w-two-thirds-l">


<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>
<!--

Time spent:

280620, 22 minutes
280620, 34 minutes
280620, 30 minutes

-->
<p>For those who ended up here looking for information about <a href="https://en.wikipedia.org/wiki/Quantum_statistical_mechanics">quantum statistical mechanics</a> or <a href="https://en.wikipedia.org/wiki/Particle_statistics">particle statistics</a>: apologies! But sometimes I feel like physicists took all the exciting names, so I’m stealing the term quanta as it relates to an observable that can take on only discrete (not continuous values). That has interesting consequences for inferential procedures based on such discrete (“quantum”) statistics, as we will see in this post.</p>
<p>Consider performing a hypothesis test for a binomial proportion <span class="math inline">\(p\)</span>. For example, imagine that you want to come to a tentative conclusion about the bias of a coin after flipping it 10 times.</p>
<p>Let <span class="math inline">\(X\)</span> be the number of times that the coin comes up heads out of 10 flips. Then <span class="math inline">\(X \sim \mathrm{Binom}(n = 10, p)\)</span> where <span class="math inline">\(p\)</span> is the bias of the coin to come up heads. We really want to show that the bias of the coin is smaller than a certain value <span class="math inline">\(p_{0}\)</span>, but we do not want to reject that the bias is greater than or equal to <span class="math inline">\(p_{0}\)</span> too easily. So we set up the left-sided hypothesis test:
<span class="math display">\[\begin{aligned} H_{0} &amp;: p \geq p_{0} \\ H_{1} &amp;: p &lt; p_{0} \end{aligned}.\]</span>
We will take <span class="math inline">\(x_{\mathrm{obs}}\)</span>, the number of observed heads out of our 10 flips, as our test statistic: the smaller the number of heads, the more evidence against the null hypothesis. We are too lazy to set up a rejection region, so we will resort to using a <span class="math inline">\(P\)</span>-value instead. Recalling that the <span class="math inline">\(P\)</span>-value is the probability of a test statistic as extreme or more extreme than the observed test statistic when the null hypothesis is true, we find that the <span class="math inline">\(P\)</span>-value is
<span class="math display">\[\begin{aligned} P(x_{\mathrm{obs}}) &amp;= \sup_{p \geq p_{0}} P_{p}(X \leq x_{\mathrm{obs}}) \\ &amp;= P_{p_{0}}(X \leq x_{\mathrm{obs}}) \end{aligned}\]</span>
Now to perform a classical hypothesis test, we use the <span class="math inline">\(P\)</span>-value as usual. We set up a significance level <span class="math inline">\(\alpha\)</span>, and reject the null hypothesis whenever our <span class="math inline">\(P\)</span>-value is less than or equal to <span class="math inline">\(\alpha\)</span>.</p>
<p>If we were dealing with a continuous test statistic, the analysis we did would be done. The <span class="math inline">\(P\)</span>-value would be less than or equal to <span class="math inline">\(\alpha\)</span> a proportion <span class="math inline">\(\alpha\)</span> of the time when <span class="math inline">\(p = p_{0}\)</span>, and even more often when <span class="math inline">\(p \geq p_{0}\)</span>, so our worst Type I Error Rate would be <span class="math inline">\(\alpha\)</span>.</p>
<p>But something is different with discrete test statistics. Let’s create a plot of the possible <span class="math inline">\(P\)</span>-values as a function of both the observed test statistic <span class="math inline">\(x_{\mathrm{obs}}\)</span> (which is colored from blue when <span class="math inline">\(x_{\mathrm{obs}} = 0\)</span> to red when <span class="math inline">\(x_{\mathrm{obs}} = n\)</span>) and the null value <span class="math inline">\(p_{0}\)</span> we want to test. We’ll create a function so we can eventually change <span class="math inline">\(n\)</span> to values other than 10:</p>
<pre class="r"><code>p.value.plot &lt;- function(n, alpha = 0.05, p0 = 1/2){
  xs &lt;- 0:n

  cols &lt;- colorspace::diverge_hcl(length(xs))
  
  plot(0, 0, cex = 0, xlim = c(0, 1), ylim = c(0, 1),
       xlab = expression(italic(p[0])),
       ylab = expression(italic(P)[italic(p)[0]](italic(X) &lt;= italic(x)[obs])))
  for (x.ind in 1:length(xs)){
    x &lt;- xs[x.ind]
    curve(pbinom(x, n, p), 
          xname = &#39;p&#39;, add = TRUE, col = cols[x.ind],
          n = 2001)
  }
  abline(h = alpha, v = p0, lty = 3)
}</code></pre>
<p>Running this, we get 11 curves, since <span class="math inline">\(x_{\mathrm{obs}}\)</span> can range from 0 to 10:</p>
<pre class="r"><code>n &lt;- 10
p.value.plot(n)</code></pre>
<p><img src="/post/2020-06-28-the-land-of-lost-significance-exact-tests-with-discrete-test-statistics_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<p>The vertical line gives us a slice through the <span class="math inline">\(P\)</span>-values when we want to test that <span class="math inline">\(p &lt; 1/2\)</span>. The horizontal line shows a desired significance level of <span class="math inline">\(\alpha = 0.05\)</span> (the favorite number of significance fetishists). And we notice something a bit shocking: if we reject when our <span class="math inline">\(P\)</span>-value is less than or equal to <span class="math inline">\(\alpha = 0.05\)</span>, we won’t reject precisely 5% of the time under the worst-case null hypothesis. Instead, we’ll reject something closer to 1% of the time: the size of our test is actually smaller than what we set out to have! The actual size of our test is the largest <span class="math inline">\(P\)</span>-value that is less than or equal to <span class="math inline">\(\alpha\)</span>, which we see is the <span class="math inline">\(P\)</span>-value corresponding to <span class="math inline">\(x_{\mathrm{obs}} = 1\)</span>:</p>
<pre class="r"><code>pbinom(1, n, 1/2) # A wee bit too big</code></pre>
<pre><code>## [1] 0.01074219</code></pre>
<p>If we took the <span class="math inline">\(P\)</span>-value for <span class="math inline">\(x_{\mathrm{obs}} = 2\)</span>, that would be just a bit too big:</p>
<pre class="r"><code>pbinom(2, n, 1/2) # A wee bit too small</code></pre>
<pre><code>## [1] 0.0546875</code></pre>
<p>The actual size of our test is therefore <span class="math inline">\(\approx 0.011\)</span>, Thus, we have “lost” an amount <span class="math inline">\(0.05 - 0.011 = 0.039\)</span> of the desired significance!</p>
<p>Moreover, we see something else: sometimes <strong>none</strong> of the <span class="math inline">\(P\)</span>-values will be less than our significance level! For example, if we wanted to take our null <span class="math inline">\(p_{0}\)</span> to be 0.2:</p>
<pre class="r"><code>p.value.plot(n, p0 = 0.2)</code></pre>
<p><img src="/post/2020-06-28-the-land-of-lost-significance-exact-tests-with-discrete-test-statistics_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>we see that none of the <span class="math inline">\(P\)</span>-values are less than or equal to <span class="math inline">\(\alpha = 0.05\)</span>. Thus, we would never reject the null hypothesis, and our Type I Error Rate would, by definition, be 0%: we’ll never reject the null hypothesis when it is true because we’ll never reject the null hypothesis!</p>
<p>The problem here is that, because the test statistic is discrete, and thus can take on only discrete values, the <span class="math inline">\(P\)</span>-value, which is just a particular function of the test statistic, is also discrete. Quantum statistics, as promised! The problem begins to go away as the sample size increases (in this case, as we flip more and more coins). In the limit, in fact, we know the problem must completely go away, since a binomial random variable will converge, by the <a href="https://en.wikipedia.org/wiki/Central_limit_theorem">Central Limit Theorem</a>, on a <a href="https://en.wikipedia.org/wiki/Normal_distribution">Gaussian random variable</a>. We can see that by creating a new plot where we consider flipping 100, rather than just 10, coins:</p>
<pre class="r"><code>n &lt;- 100
p.value.plot(n)</code></pre>
<p><img src="/post/2020-06-28-the-land-of-lost-significance-exact-tests-with-discrete-test-statistics_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>Clearly the <span class="math inline">\(P\)</span>-values are beginning to fill up the continuum from 0 to 1, especially so near where <span class="math inline">\(p_{0} = 1/2\)</span>. In this case, we can find the actual size of our test when we use <span class="math inline">\(\alpha = 0.05\)</span> in the same way: find the largest <span class="math inline">\(P\)</span>-value that is still less than or equal to 0.05:</p>
<pre class="r"><code>xs &lt;- 0:n
Ps &lt;- pbinom(xs, n, 1/2)

x.star &lt;- tail(xs[which(Ps &lt;= 0.05)], 1)</code></pre>
<p>And again, this gives us a <span class="math inline">\(P\)</span>-value that is a bit too small:</p>
<pre class="r"><code>pbinom(x.star, n, 1/2)</code></pre>
<pre><code>## [1] 0.04431304</code></pre>
<p>but the next largest <span class="math inline">\(P\)</span>-value is a bit too big:</p>
<pre class="r"><code>pbinom(x.star+1, n, 1/2)</code></pre>
<pre><code>## [1] 0.06660531</code></pre>
<p>In fact, we can see how the actual size of the test using <span class="math inline">\(\alpha = 0.05\)</span> as our cutoff varies as we increase <span class="math inline">\(n\)</span>:</p>
<pre class="r"><code>find.size = function(n, alpha = 0.05, p0 = 1/2){
  xs &lt;- 0:n
  Ps &lt;- pbinom(xs, n, p0)
  
  tail(Ps[Ps &lt;= alpha], 1)
}

find.size &lt;- Vectorize(find.size, vectorize.args = &#39;n&#39;)

ns &lt;- 1:200

plot(ns, find.size(ns), ylim = c(0, 0.05), type = &#39;b&#39;, pch = 16, cex = 0.5,
     xlab = expression(italic(n)), ylab = expression(Size(italic(n))))
abline(h = 0.05, lty = 3)</code></pre>
<p><img src="/post/2020-06-28-the-land-of-lost-significance-exact-tests-with-discrete-test-statistics_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<p>We see that, by construction, the actual size is always less than or equal to 0.05, and it gets closer, but in a sawtooth way, to the desired significance level. If we take <span class="math inline">\(n\)</span> to be quite large, we see:</p>
<pre class="r"><code>ns &lt;- 1:2000

plot(ns, find.size(ns), ylim = c(0, 0.05), type = &#39;b&#39;, pch = 16, cex = 0.5,
     xlab = expression(italic(n)), ylab = expression(Size(italic(n))))
abline(h = 0.05, lty = 3)</code></pre>
<p><img src="/post/2020-06-28-the-land-of-lost-significance-exact-tests-with-discrete-test-statistics_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<p>so the size, at least for certain values of <span class="math inline">\(n\)</span>, only <strong>very slowly</strong> approaches the desired significance level.</p>
<p>There’s almost certainly some interesting mathematics in the limiting behavior of the size of this test, and that mathematics has almost certainly been explored! But we will leave that for now. In the next two posts, we will discuss methods for handling the conservativeness of tests that rely on discrete test statistics: randomized rejection and mid <span class="math inline">\(P\)</span>-values.</p>
<ul class="pa0">
  
   <li class="list">
     <a href="/tags/statistics" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">statistics</a>
   </li>
  
</ul>
<div class="mt6">
      
      
      </div>
    </section>

    <aside class="w-30-l mt6-l">




  <div class="bg-light-gray pa3 nested-list-reset nested-copy-line-height nested-links">
    <p class="f5 b mb3">Related</p>
    <ul class="pa0 list">
	   
	     <li  class="mb2">
          <a href="/post/salvaging-lost-significance-via-randomization-randomized-p-values-for-discrete-test-statistics/">Salvaging Lost Significance via Randomization: Randomized \(P\)-values for Discrete Test Statistics</a>
        </li>
	    
    </ul>
</div>

</aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="/" >
    &copy; 2020 Practically Insignificant
  </a>
    <div>











</div>
  </div>
</footer>

    

  <script src="/dist/js/app.3fc0f988d21662902933.js"></script>


  </body>
</html>
