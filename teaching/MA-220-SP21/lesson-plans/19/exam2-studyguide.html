<script src='https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>
<h1>Study Guide for Exam 2</h1>

<h2>Exam Format</h2>

<p>This will be an open-book, open-notes exam. You may (and should) use RStudio Cloud during the exam. <b>You may not collaborate with anyone, nor use the internet in <em>any other way</em>, during this exam.</b>

<p>The exam will consist of 6 problems, 5 of which will be open-ended and 1 of which will be multiple choice. All open-ended problems will be multi-part.

<h2>Advice for Preparing for the Exam</h2>

This is a mathematics exam. As such, you will be expected to <strong>do mathematics</strong>. A common misconception made by students is that, in preparing for a mathematics exam, it suffices to make sure you can understand the solution to a given problem <strong>with the solution in front of you</strong>. The exam, however, tests your ability to <strong>solve the problem yourself from scratch</strong>. Thus, you should practice solving problems from scratch in preparation for the exam. The homework and quizzes are part of this practice, but only completing those once will likely not lead to a strong performance on the exam.

<p>With the ultimate goal of solving problems yourself from scratch in mind, a possible study check list is below:
<ol>
	<li> Make sure you can correctly answer all of the Anki cards I provided, and any additional Anki cards you made. If you are still unclear on the material on any of the Anki cards, <strong>see me</strong>.
	<li> Exam questions will be modeled off of in-class examples, homework problems, and quiz problems. As such, go through homework and quiz problems, <strong>especially those you found difficult or that were marked as incorrect / incomplete</strong>, and make sure you can solve them from scratch, <strong>without the solution in front of you.</strong>
	<ul>
		<li>I have provided blank copies of all of the quizzes on eCampus so you can re-solve a given problem from scratch.
		<li>Since problems on the exam will not come tagged with the chapter / section relevant to their solutions, you might try solving the quiz and homework problems in a random order. If you would like help with this, I can show you how to construct a randomized list of problems using R.
	</ul>
	<li> Review the compilation of learning objectives below, and make sure you can perform each action below <strong>without your notes or book</strong>. If there is a particular learning objective you are unclear on, <strong>email or see me</strong>.
	<li><strong>Cramming</strong> (studying right before the exam) combined with <strong>massed practice</strong> (solving lots of problems all at once) is an <strong>ineffective</strong> study strategy. Instead, <strong>distribute</strong> your study sessions <strong>over the remaining time until the exam</strong>. Study for at most 60 to 90 minutes at a time, and <strong>take breaks</strong>, whether legitimate breaks (go for a walk, hang out with friends, etc.), or a transition to studying for another course. The sooner before the exam you start studying, the better.
</ol>

<p>To do well on the exam, you should be able to do the following:</p>

<h3> Chapter 3: Discrete Random Variables </h3>

<p><strong>Section 3.2: Probability Distributions for Discrete Random Variables</strong></p>

<ol>
<li>State the experiment that is modeled by a discrete uniform random variable.</li>
<li>State the probability mass function and cumulative distribution function for a discrete uniform random variable with a given range.</li>
<li>Use R to simulate a discrete uniform random variable.</li>
<li>State the experiment that is modelled by a Bernoulli random variable.</li>
<li>State the probability mass function and cumulative distribution function for a Bernoulli random variable.</li>
<li>Use R to simulate a Bernoulli variable.</li>
<li>State the experiment that is modelled by a geometric random variable.</li>
<li>State the probability mass function and cumulative distribution function for a geometric random variable.</li>
<li>Use R to simulate a geometric variable.</li>
<li>Describe how a probability histogram represents a probability mass function, and construct a probability histogram given a probability mass function and vice versa.</li>
<li>Relate probability histograms to the other histograms we have learned in class: frequency, relative frequency, and density histograms.</li>
</ol>

<p><strong>Section 3.3: Expected Values of Discrete Random Variables</strong></p>

<ol>
<li>Define the expected value of a discrete random variable <span class="math">\(X\)</span>, and compute <span class="math">\(X\)</span>&#8217;s expected value given its probability mass function.</li>
<li>Give a frequency interpretation of the expected value of a random variable <span class="math">\(X\)</span>.</li>
<li>Recognize the convention of using Greek letters for parameters of a random variable, and their Roman counterpart for statistics of a sample. For example, <span class="math">\(\sigma\)</span> for the standard deviation of a random variable and and <span class="math">\(s\)</span> for the standard deviation of a sample.</li>
<li>Compute the expected value of a random variable <span class="math">\(Y = g(X)\)</span> defined through a function <span class="math">\(g\)</span> of a random variable <span class="math">\(X\)</span> with a known probability mass function.</li>
<li>Simplify expectations of the form <span class="math">\(E[a X + b]\)</span> and<br/>
<span class="math">\(E\left[\sum\limits_{j = 1}^{n} g_{j}(X)\right]\)</span> directly, without resorting to the definition of expectation.</li>
<li>Define the variance of a discrete random variable <span class="math">\(X\)</span>, and compute <span class="math">\(X\)</span>&#8217;s variance given its probability mass function.</li>
<li>Define the standard deviation of a random variable.</li>
<li>Use the &#8216;variance shortcut&#8217; to compute the variance of a random variable.</li>
<li>Simplify variances (standard deviations) of the form <span class="math">\(\text{Var}(a X + b)\)</span> (<span class="math">\(\sigma_{a X + b}\)</span>) directly, without resorting to the definition of variance (standard deviation).</li>
</ol>

<p><strong>Section 3.5: The Binomial Probability Distribution</strong></p>

<ol>
<li>Identify the <strong>4</strong> characteristics of a binomial experiment, and determine whether a given experiment has those characteristics.</li>
<li>Determine the sample space for a given binomial experiment.</li>
<li>State in what way a binomial random variable acts as a function from the sample space of a binomial experiment. That is, what does the binomial random variable output for a given outcome in the sample space?</li>
<li>State the probability mass function for a binomial random variable with parameters <span class="math">\(n\)</span> and <span class="math">\(p\)</span>.</li>
<li>Identify the parameters of a binomial random variable for a given binomial experiment.</li>
<li>Use the formula for the probability mass function of a binomial random variable to compute <span class="math">\(P(X = x; n, p)\)</span> directly.</li>
<li>Use R to compute binomial probabilities.</li>
<li>State the mean and variance of a binomial random variable, and compute the mean and variance from a given binomial experiment.</li>
</ol>

<h3> Chapter 4: Continuous Random Variables </h3>

<p><strong>Section 4.1: Probability Density Functions and Cumulative Distribution Functions</strong></p>

<ol>
<li>Give examples of quantities that could be modeled using a continuous random variable.</li>
<li>Recognize and explain the correspondence between density histograms for data and probability density functions for random variables.</li>
<li>Given a probability density function <span class="math">\(f\)</span> for a continuous random variable <span class="math">\(X\)</span> and a query region <span class="math">\([a, b]\)</span>, determine <span class="math">\(P(X \in [a, b]) = P(a \leq X \leq b)\)</span> using <span class="math">\(f\)</span>.</li>
<li>State the two sufficient conditions for a function <span class="math">\(f\)</span> to be a valid probability density function, and identify when a given function <span class="math">\(f\)</span> does or does not satisfy these conditions.</li>
<li>Given that a probability density function is proportional to a known function, i.e. <span class="math">\(f(x) = c g(x)\)</span>, determine the constant <span class="math">\(c\)</span> that makes <span class="math">\(f\)</span> a probability density function.</li>
<li>Define the cumulative distribution function of a continuous random variable, and compute the cumulative distribution function using the random variable&#8217;s probability density function.</li>
<li>Specify what additional property, beyond the four properties shared by all cumulative distribution functions, unique to the cumulative distribution function of a continuous random variable.</li>
<li>Compute a probability query <span class="math">\(P(X \in (a, b)) = P(a < X < b)\)</span> using the cumulative distribution function of a continuous random variable.</li>
<li>Determine the probability density function of a continuous random variable from its cumulative distribution function.</li>
</ol>

<p><strong>Section 4.2: Expected Values and Moment Generating Functions</strong></p>

<ol>
<li>Define the expected value of a continuous random variable <span class="math">\(X\)</span>, and compute <span class="math">\(X\)</span>&#8217;s expected value given its probability density function.</li>
<li>Recognize the correspondence between sums and probability mass functions for discrete random variables and integrals and probability density functions for continuous random variables.</li>
<li>Compute the expected value of a random variable <span class="math">\(Y = g(X)\)</span> defined through a function <span class="math">\(g\)</span> of a continuous random variable <span class="math">\(X\)</span> with a known probability density function.</li>
<li>Simplify expectations of the form <span class="math">\(E[a X + b]\)</span> and <span class="math">\(E\left[\sum\limits_{j = 1}^{n} g_{j}(X)\right]\)</span> directly, without resorting to the definition of expectation.</li>
<li>Define the variance of a continuous random variable <span class="math">\(X\)</span>, and compute <span class="math">\(X\)</span>&#8217;s variance given its probability density function.</li>
<li>Use the &#8216;variance shortcut&#8217; to compute the variance of a random variable.</li>
<li>Simplify variances (standard deviations) of the form <span class="math">\(\text{Var}(a X + b)\)</span> (<span class="math">\(\sigma_{a X + b}\)</span>) directly, without resorting to the definition of variance (standard deviation).</li>
</ol>

<p><strong>Section 4.3: The Normal Distribution</strong></p>

<ol>
<li>State the probability density function for a Gaussian random variable with parameters <span class="math">\(\mu\)</span> and <span class="math">\(\sigma^{2}\)</span>.</li>
<li>Recognize the notation <span class="math">\(X \sim N(\mu, \sigma^{2})\)</span> as indicating that <span class="math">\(X\)</span> is a Gaussian random variable with parameters <span class="math">\(\mu\)</span> and <span class="math">\(\sigma^{2}\)</span>.</li>
<li>State the mean and variance of a Gaussian random variable with parameters <span class="math">\(\mu\)</span> and <span class="math">\(\sigma^{2}\)</span>.</li>
<li>Sketch a graph of the probability density function for a Gaussian random variable with parameters <span class="math">\(\mu\)</span> and <span class="math">\(\sigma^{2}\)</span>, getting the general <strong>shape</strong> and <strong>placement</strong> of the probability density function correct, and use this graph to reason about the area under consideration for a given probability query.</li>
<li>Sketch a graph of the cumulative distribution function for a Gaussian random variable with parameters <span class="math">\(\mu\)</span> and <span class="math">\(\sigma^{2}\)</span>, getting the general <strong>shape</strong> and <strong>placement</strong> of the cumulative distribution function correct.</li>
<li>State the definition of a standard Gaussian random variable, and recognize the notation that <span class="math">\(Z\)</span> will often be used to denote a standard Gaussian random variable.</li>
<li>Recognize and use the convention of denoting the cumulative distribution function for a standard Gaussian random variable via <span class="math">\(\Phi(z) = P(Z \leq z)\)</span>.</li>
<li>Standardize a random variable <span class="math">\(X \sim N(\mu, \sigma^{2})\)</span>, and indicate the distribution of the transformed random variable.</li>
<li>Compute probability queries for a Gaussian random variable using R.</li>
<li>Define the <span class="math">\(p\)</span>-th percentile of a Gaussian random variable, and determine the <span class="math">\(p\)</span>-th percentile using R.</li>
</ol>

<h3> Chapter 6: Statistics of Random Samples and Their Sampling Distributions </h3>

<p><strong>Section 6.1: Statistics and Their Distributions</strong></p>

<ol>
<li>Define a random sample from a population.</li>
<li>Explain why a statistic of a random sample is itself a random variable.</li>
<li>Define the sampling distribution of a statistic.</li>
<li>Given a probability model for how a random sample is generated, construct the sampling distribution of a statistic of that random sample for small sample sizes (<span class="math">\(n = 2\)</span> or <span class="math">\(3\)</span>).</li>
</ol>

<p><strong>Section 6.2: The Distribution of the Sample Mean</strong></p>

<ol>
<li>Recognize and explain the notation <span class="math">\(X_{1}, X_{2}, \ldots, X_{n} \stackrel{\text{iid}}{\sim} \text{D}\)</span> for a random sample from a population with distribution D.</li>
<li>Compute the mean and variance of the sample mean for a random sample <span class="math">\(X_{1}, X_{2}, \ldots, X_{n} \stackrel{\text{iid}}{\sim} \text{D}\)</span> of size <span class="math">\(n\)</span> from a population with mean <span class="math">\(\mu\)</span> and variance <span class="math">\(\sigma^{2}\)</span>.</li>
<li>Distinguish between the mean and variance of a population and the mean and variance of the sample mean of a random sample from that population.</li>
<li>State the premises (conditions) and conclusion of the Central Limit Theorem.</li>
<li>Explain in what sense the Central Limit Theorem is an <strong>asymptotic</strong> result.</li>
<li>State under what conditions the Central Limit Theorem-based approximation for the sampling distribution of the sample mean works well for small sample sizes.</li>
<li>Use the Central Limit Theorem to approximate the sampling distribution of the sample mean for a random sample from a population with known mean and variance.</li>
<li>Use the Central Limit Theorem to approximate the sample total for a random sample from a population with known mean and variance.</li>
</ol>

<h3> Chapter 7: Point Estimators</h3>

<p><strong>Section 7.1: Point Estimation &mdash; General Concepts and Criteria</strong></p>

<ol>
<li>Compare and contrast descriptive and inferential statistics in terms of populations/samples and parameters / statistics.</li>
<li>Explain why you can never answer a question about a <strong>population</strong> directly from a sample without making an inference.</li>
<li>State the three main types of inferential procedures we will consider in this course, and describe them in plain English.</li>
<li>Define point estimator, and state what a point estimator is an estimator <strong>for</strong>.</li>
<li>Distinguish between a point estimator (the procedure) and a point estimate (an application of the procedure to a particular sample).</li>
<li>State common point estimators for population parameters, including point estimators for population means, variances, and success probabilities.</li>
<li>Given a collection of point estimators and their expected values and variances, come up with a rough ranking of how &#8220;good&#8221; the point estimators are.</li>
<li>Recognize the statistical notation of using <span class="math">\(\theta\)</span> for a generic parameter of a population, and <span class="math">\(\widehat{\theta}\)</span> for a point estimator of that parameter.</li>
<li>Define the standard error of a point estimator, and compute the standard error of a point estimator given its sampling distribution.</li>
</ol>

<h3> Chapter 8: Interval Estimators and Confidence Intervals</h3>

<p><strong>Section 8.1: Basic Properties of Confidence Intervals</strong></p>

<ol>
<li>Determine the margin of error for the sample mean from a Gaussian population with known standard deviation <span class="math">\(\sigma\)</span> at a confidence level <span class="math">\(c\)</span>.</li>
<li>Recognize the relationship between a confidence level <span class="math">\(c\)</span> and tail value <span class="math">\(\alpha\)</span>, and state how these specify the probability in the tails or body of a given distribution.</li>
<li>Determine the critical value <span class="math">\(z_{\alpha}\)</span> for a standard Gaussian random variable using R&#8217;s <tt>qnorm</tt>.</li>
<li>Define interval estimator and confidence interval, and make an analogy between them and point estimators and point estimates.</li>
<li>Construct a <span class="math">\(c = 1 - \alpha\)</span> confidence interval for a population mean <span class="math">\(\mu\)</span> using a random sample from a Gaussian population when the population standard deviation <span class="math">\(\sigma\)</span> is known.</li>
<li>Sketch the confidence interval from the previous learning objective.</li>
</ol>

<p><strong>Section 8.3: Intervals Based on a Normal Population Distribution</strong></p>

<ol>
<li>Give a constructive definition of a <span class="math">\(t\)</span>-distributed random variable <span class="math">\(T\)</span> using a random sample from a Gaussian population.</li>
<li>Determine the parameter of a <span class="math">\(t\)</span>-distributed random variable <span class="math">\(T\)</span> constructed using a random sample from a Gaussian population.</li>
<li>Describe the general properties of the probability density function of a <span class="math">\(t\)</span>-distributed random variable as compared to a standard Gaussian random variable including where each is centered, the symmetry properties of each, and the &#8220;fatness&#8221; of the tails of each.</li>
<li>Determine the critical value <span class="math">\(t_{\alpha, \nu}\)</span> for a random variable <span class="math">\(T\)</span> that is <span class="math">\(t\)</span>-distributed with parameter <span class="math">\(\nu\)</span> using R&#8217;s <tt>qt</tt>.</li>
<li>Construct a <span class="math">\(c = 1 - \alpha\)</span> confidence interval for a population mean <span class="math">\(\mu\)</span> using a random sample from a Gaussian population when the population standard deviation <span class="math">\(\sigma\)</span> is unknown.</li>
<li>Sketch the confidence interval from the previous learning objective.</li>
<li>Reason about what confidence interval we have covered, if any, is appropriate for the population mean given a description of a sample from that population.</li>
</ol>