<script src='https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>

<p><strong>Chapter 7: Multivariate Distributions</strong></p>

<ol>
<li>Define the joint moment generating function for a random vector <span class="math">\(\mathbf{X}\)</span>, and compare it to the moment generating function of a random variable <span class="math">\(X\)</span>.</li>
<li>Compute non-central product moments from a joint moment generating function.</li>
<li>Determine marginal moment generating functions from a joint moment generating function.</li>
<li>Recognize that the expectation <span class="math">\(E[g(X) h(Y)]\)</span> factors, for any <span class="math">\(g\)</span> and <span class="math">\(h\)</span>, when <span class="math">\(X\)</span> and <span class="math">\(Y\)</span> are independent.</li>
<li>Recognize that joint moment generating functions factor when components of the governing random vector are independent.</li>
<li>Use the joint moment generating function of a random vector <span class="math">\(\mathbf{X}\)</span> to determine the moment generating function of a linear combination of the components of <span class="math">\(\mathbf{X}\)</span>.</li>
<li>Relate the probability density function for a Gaussian random vector to the probability density function for a Gaussian random variable.</li>
<li>Recognize that the linear combination of Gaussian random variables is itself Gaussian, and determine the distribution of the linear combination given information about the first and second moments of the random variables.</li>
<li>Evaluate probabilities such at <span class="math">\(P(a X + b Y > c)\)</span> when <span class="math">\(X\)</span> and <span class="math">\(Y\)</span> are Gaussian random variables with known first and second moments.</li>
</ol>