<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>
<title>MA 220-02 Probability and Statistics I (Spring 2020)</title>

<a href="http://www.thirdorderscientist.org"><em>David Darmon</em></a>

<h1>MA 220-02, Probability and Statistics I</h1>

<h2>Spring 2020</h2>


<center>
Section 02: Monday and Wednesday, 11:40 AM &mdash; 1:00 PM, Howard Hall 307
</center>

<P>Here's the official description:
<blockquote>To provide an axiomatic, calculus-based approach to probability and introductory statistics. The course is built around the process of performing a statistical analysis; posing the question, collecting the data, describing the data, analyzing and modeling the data, and drawing inferences from the data regarding the original question. Specific topics covered include sampling, descriptive analysis of data, probability, random variables, discrete and continuous distributions, expectation, confidence intervals, one sample hypothesis testing, chi-square analyses, correlation and regression.</blockquote>

<P>This course covers the process of statistical analysis from beginning to end. That process, in broad strokes, is as follows: we pose a scientific question, determine what experiments or observations might provide data towards answering that question, develop approaches to collecting that data, summarize the resulting data, and derive inferences relevant to the original scientific question. In the process, we will learn about sampling, descriptive statistics, probability, probability models, inferential statistics, confidence intervals, hypothesis tests, and regression. A special emphasis will be given to common pitfalls in statistical analysis you are likely to see 'in the wild', including mis-interpretations / mis-understandings of statistical procedures, the conflation of association and causation, and the reproducibility crisis in psychology, medicine, and nutrition. 

<h4>Prerequisites</h4>

<P>MA 116 or MA 118 or MA 126 passed with a grade of C- or higher.

<h4>Professor</h4>

<table>
<tr><td>Dr. David Darmon</td> <td></td><td>ddarmon [at] monmouth.edu</td></tr>
<tr><td></td><td></td><td>Howard Hall 241</td></tr>
</table>

<h2>Topics, Notes, Readings</h2>

<P>This is currently a <em>tentative</em> listing of topics, in order.


<dl>
	<dt><em>Introduction:</em> What is statistics? Where do data come from? Experimental versus observational studies. Types of data.
    <dt><em>Descriptive statistics as summaries of data:</em> Summaries of the entire data distribution: rug plot, dot plot, histogram, box plot. Measures of center: mean, median, mode. Measures of variation: range, standard deviation, mean absolute deviation.
    <dt><em>Probability:</em> The origin of probability in games of chance. The interpretation of probability. Computing probabilities involving two or more events using the addition and multiplication rules. Conditional probability and independence.
    <dt><em>Discrete random variables:</em> Random variables as 'numbers that could have been otherwise.' Probability mass functions. Parametric models for discrete random variables: uniform, Bernoulli, binomial, geometric, and Poisson. Moments of discrete random variables.
    <dt><em>Continuous random variables:</em> Summarizing quantitative data with histograms. From histograms to probability density functions. Parametric models for continuous random variables: uniform, exponential, normal. Moments of continuous random variables. The normal distribution and its properties. Using the normal distribution to approximate the binomial distribution.
    <dt><em>Statistics and their sampling distributions:</em> From forward probability to inverse probability. Statistics as functions of a data set. The sampling distribution of the sample mean. The Law of Large Numbers and the Central Limit Theorem.
    <dt><em>Estimators and point estimation:</em> Making an educated guess at a population parameter using a point estimator. Desirable properties of point estimators. Methods for deriving point estimators: method of moments and maximum likelihood estimation.
    <dt><em>Confidence intervals:</em> Confidence intervals as interval estimators. The interpretation of confidence intervals. Confidence intervals for population means and proportions.
    <dt><em>Hypothesis tests:</em> Hypothesis tests for population means and proportions. Components of a hypothesis test. Types of error in hypothesis testing. Scientific hypotheses and statistical hypotheses. Statistical significance and practical significance. Using confidence intervals for hypothesis tests. Using confidence intervals to distinguish between practical and statistical significance. <em>P</em>-values.
    <dt><em>Everything but the kitchen sink:</em> Two-sample tests for population means and their associated confidence intervals. Two-sample tests for population proportions and their associated confidence intervals. 
    <dt><em>Correlation and regression:</em> Exploratory data analysis for two or more quantitative variables. Pearson's correlation coefficient. Confidence interval and hypothesis test for the Pearson correlation between two quantitative variables. Association does not imply causation. Simple linear regression. Interpretation of regression coefficients. Multiple linear regression. Predictive and causative statements.
</dl>

See the <a href = "#schedule">end of this page</a> for the current lecture schedule, subject to revision.  Homework and additional resources will be linked there, as available.

<h2>Course Mechanics</h2>

<h4>Office Hours</h4>

<p>I will have office hours at the following four times each week:

<center><table>
    <tr><td>Monday, &nbsp;&nbsp;10:00&mdash;11:00 AM</td> <td>Howard Hall 241</td></tr>
</td></tr>
    <tr><td>Tuesday, &nbsp;&nbsp;03:00&mdash;04:00 PM</td> <td>Howard Hall 241</td></tr>
</td></tr>
    <tr><td>Thursday, 10:00&mdash;11:00 AM</td> <td>Howard Hall 241</td></tr>
</td></tr>
    <tr><td>Thursday, 03:00&mdash;04:00 PM</td> <td>Howard Hall 241</td></tr>
</table></center>

<p>I have an open-door policy during those times: you can show up unannounced. If you cannot make the scheduled office hours, please e-mail me about making an appointment.

<p>If you are struggling with the homework, having difficulty with the quizzes, or just want to chat, please visit me during my office hours. I am here to help.

<h4>Grading Policy</h4> 

Your final grade will be determined by the following weighting scheme:

<dl>
	<dd> 45% for 2 in-class exams (22.5% each)
	<dd> 25% for a cumulative final exam
	<dd> 15% for homework problem sets
	<dd> 15% for quizzes
</dl>

I will use the standard 10-point breakdown to assign letter grades to numerical grades:
<ul>
	<li> \([90, 100] \to \text{A}\)
	<li> \([80, 90) \,\,\, \to \text{B}\)
	<li> \([70, 80) \,\,\, \to \text{C}\)
	<li> \([60, 70) \,\,\, \to \text{D}\)
	<li> \([0, 60) \,\,\,\,\,\, \to \text{F}\)
</ul>
with pluses and minuses assigned by dividing the intervals into thirds.

<h4>Extra Credit</h4>

<p> In addition to the main categories above, there are <strong>two</strong> opportunities for extra credit:

<dl>
	<dd> +5% for use of Anki (<a href = "MA-220-SP20/additional-syllabus-pages/preclass-prep-instructions.html">Instructions</a>)
	<dd> +5% for post-class reflections (<a href = "MA-220-SP20/additional-syllabus-pages/postclass-reflection.html">Instructions</a>)
</dl>

<p> <strong>Note:</strong> These are the <strong>only</strong> opportunities for extra credit in this course.

<h4>Homework</h4>

Homework will be assigned at the end of every class meeting, and listed in the <a href="#schedule">Schedule</a> section of this page. Homework assignments are due at the beginning of the next class meeting.

<h4>Quizzes</h4>

<p> Quizzes will be given during the first 10 minutes of some class sessions. Quizzes may not be every week: I will announce quizzes at least one class session before they will occur. If you miss a quiz your grade will be zero for that quiz. Your lowest two quiz grades of the semester will be dropped.

<h4>Class Participation</h4>

I expect you to be fully engaged during each class, to ask questions when confused, and to attempt to answer questions when called on. Attempting to answer a question is more important than getting the correct answer.

<h4>Attendance</h4>

Required. If you expect to miss 2-3 sessions of the course, you should take the course during another semester.

<h4>Examination Absences</h4>

If you miss an examination your grade will be zero for that exam.  If you know you will be absent for an exam you must let me know at least one week in advance to schedule a make-up exam.

<h4>Textbook</h4>

<P>The <strong>required</strong> textbook is:
<ul>
<li>Jay L. Devore and Kenneth N. Berk. <em>Modern mathematical statistics with applications</em>, 1st Edition (Cengage Learning, 2007). <a href = "http://mubookstore.monmouth.edu/TextBookDetail.aspx?BookPriceID=2292893&MBSNumber=747336&SecID=9614832&trm=SPRING%2019#.XBl34y2ZNhE">Link to University Store</a>
</ul>

<h4>Collaboration, Cheating, and Plagiarism</h4>

All submitted work should be your own. You are welcome and encouraged to consult with others while working on an assignment, including other students in the class and tutors in the <a href="https://www.monmouth.edu/department-mathematics/math-learning-center/">Mathematics Learning Center</a>.  However, whenever you have had assistance with a problem, you must state so at the beginning of the problem solution.  Unless this mechanism is abused, there will be no reduction in credit for using and reporting such assistance.  This policy applies to both individual and group work. In group work, you only need to acknowledge help from outside the group. This policy does <b>not</b> apply to examinations.

<h4>Statement on Special Accommodations</h4>

Students with disabilities who need special accommodations for this class are encouraged to meet with me or the appropriate disability service provider on campus as soon as possible.  In order to receive accommodations, students must be registered with the appropriate disability service provider on campus as set forth in the student handbook and must follow the University procedure for self-disclosure, which is stated in the University <em>Guide to Services and Accommodations for Students with Disabilities</em>.  Students will not be afforded any special accommodations for academic work completed prior to the disclosure of the disability, nor will they be afforded any special accommodations prior to the completion of the documentation process with the appropriate disability office.

<div id="R"><h2>R</h2></div>

<P>We will use R, a programming language for statistical computing, throughout the semester for in-class activities and homework assignments. I will cover the relevant features of R throughout the course.

<p>You can access R from any web accessible computer using <a href = "https://rstudio.cloud">RStudio Cloud</a>. You will need to create an account on RStudio Cloud from their <a href = "https://login.rstudio.cloud/register">Registration page</a>. I will send out a link via email for you to join a Space on RStudio Cloud for this course. Resources for homeworks, labs, etc., will be hosted on RStudio Cloud for easy access.
	
<p>You can also install R on your personal computer, if you have one. You can install R by following the instructions <a href="https://cran.rstudio.com/bin/windows/base/">for Windows here</a>, <a href="https://cran.rstudio.com/bin/macosx/">for macOS here</a>, or <a href="https://cran.rstudio.com/bin/linux/">for Linux here</a>. You will also want to install RStudio, and Integrated Development Environment for R, which you can find <a href="https://www.rstudio.com/products/rstudio/download/#download">here</a>.

<p>We will use R as a scripting language and statistical calculator, and thus will not get into the nitty-gritty of programming in R. We will largely use functionality built into the <tt>mosaic</tt> library in R. You can find a comprehensive tutorial to using R and <tt>mosaic</tt> <a href="https://cran.r-project.org/doc/contrib/Horton+Pruim+Kaplan_MOSAIC-StudentGuide.pdf">here</a>.

<div id="anki"><h2>Anki</h2></div>

<P> As stated in the <strong>Extra Credit</strong> section, you will have the opportunity to use <a href = "https://ankiweb.net/about">Anki</a> for spaced retrieval practice throughout the semester. Anki is open-source, free (as in both <a href = "https://en.wikipedia.org/wiki/Gratis_versus_libre"><em>gratis</em> and <em>libre</em></a>) software. You can download Anki to your personal computer from <a href = "https://apps.ankiweb.net/#download">this link</a>. If you have ever used flashcards, then Anki should be fairly intuitive. If you would like more details you can find Anki's User Manual <a href = "https://apps.ankiweb.net/docs/manual.html">here</a>.

<div id="schedule"><h2>Schedule</h2></div>

<strong>Subject to revision</strong>.  Assignments and solutions will all be linked here, as they are available.  All readings are from the textbook by Devore and Berk unless otherwise noted.

<dl>
<dt>Prior to January 22, Lecture 0:
	<dd><b>Topics: </b>Pre-class assessment.
	<dd><a href="MA-220-SP20/lesson-plans/0/homework.html">Pre-class Assignments</a>

<dt>January 22, Lecture 1:
	<dd><b>Topics: </b>Introduction to class. What is statistics? Where do data come from? Types of data. Sampling techniques. Collecting data. Bias in data collection.
	<dd><b>Sections: </b>1.1, Excerpt from Triola & Triola
	<dd><a href="MA-220-SP20/lesson-plans/1/learning-objectives.html">Learning Objectives</a>
	<dd><a href="MA-220-SP20/lesson-plans/1/homework.html">Homework 1</a>

<dt>January 27, Lecture 2:
	<dd><b>Topics: </b>Collecting data. Experimental versus observational studies. Confounding in observational studies. Summarizing data. Rug plots, histograms, box plots. Introduction to R.
	<dd><b>Sections: </b>1.1, 1.2
	<dd><a href="MA-220-SP20/lesson-plans/2/learning-objectives.html">Learning Objectives</a>
	<dd><a href="MA-220-SP20/lesson-plans/2/homework.html">Homework 2</a>
	

<dt>January 29, Lecture 3:
	<dd><b>Topics: </b>Summaries of center: mean, median, mode. Summaries of spread: standard deviation, range, mean absolute error.
	<dd><b>Sections: </b>1.3, 1.4
	<dd><a href="MA-220-SP20/lesson-plans/3/learning-objectives.html">Learning Objectives</a>
	<dd><a href="MA-220-SP20/lesson-plans/3/lab1.html">Lab 1</a>
	<dd><a href="MA-220-SP20/lesson-plans/3/homework.html">Homework 3</a>

<dt>February 3, Lecture 4:
	<dd><b>Topics: </b>Random chance and probability. Probabilities and their interpretation. The addition rule for probabilities. Using Venn diagrams to reason about probabilities.
	<dd><b>Sections: </b>2.1, 2.2
	<dd><a href="MA-220-SP20/lesson-plans/4/learning-objectives.html">Learning Objectives</a>
	<dd><a href="MA-220-SP20/lesson-plans/4/homework.html">Homework 4</a>

<dt>February 5, Lecture 5:
	<dd><b>Topics: </b>Conditional probability. The multiplication rule for probabilities. Law of Total Probability. Bayes' Rule.
	<dd><b>Sections: </b>2.4
	<dd><a href="MA-220-SP20/lesson-plans/5/learning-objectives.html">Learning Objectives</a>
	<dd><a href="MA-220-SP20/lesson-plans/5/homework.html">Homework 5</a>

<dt>February 10, Lecture 6:
	<dd><b>Topics: </b>Independence of events. Counting.
	<dd><b>Sections: </b>2.3, 2.5
	<dd><a href="MA-220-SP20/lesson-plans/6/learning-objectives.html">Learning Objectives</a>
	<dd><a href="MA-220-SP20/lesson-plans/6/homework.html">Homework 6</a>

<dt>February 12, Lecture 7:
	<dd><b>Topics: </b>Random variables: numbers that could have been otherwise. Discrete random variables. The probability mass function \(p\). The cumulative distribution function \(F\).
	<dd><b>Sections: </b>3.1, 3.2
	<dd><a href="MA-220-SP20/lesson-plans/7/learning-objectives.html">Learning Objectives</a>
	<dd><a href="MA-220-SP20/lesson-plans/7/homework.html">Homework 7</a>

<dt>February 17, Lecture 8:
	<dd><b>Topics: </b>More on discrete random variables. Some important discrete random variables: discrete uniform, Bernoulli, and geometric. Simulating random variables using R. Expectation of a discrete random variable.
	<dd><b>Sections: </b>3.2, 3.3
	<dd><a href="MA-220-SP20/lesson-plans/8/learning-objectives.html">Learning Objectives</a>
	<dd><a href="MA-220-SP20/lesson-plans/8/homework.html">Homework 8</a>

<dt>February 19, Lecture 9:
	<dd><b>Topics: </b>More on discrete random variables. Interpreting the expected value of a random variable. Expectation as a linear operator: \(E(a X + b) = a E(X) + b\). Expectation of functions of a discrete random variable. Variance of a discrete random variable. Binomial experiments.
	<dd><b>Sections: </b>3.3, 3.5
	<dd><a href="MA-220-SP20/lesson-plans/9/learning-objectives.html">Learning Objectives</a>
	<dd><a href="MA-220-SP20/lesson-plans/9/homework.html">Homework 9</a>

<dt>February 24, Lecture 10:
	<dd><b>Topics: </b>Exam 1.
	<dd><b>Sections: </b>Chapters 1 - 3
	<dd><a href="MA-220-SP20/lesson-plans/10/exam1-studyguide.html">Exam 1 Study Guide</a>

<dt>February 26, Lecture 11:
	<dd><b>Topics: </b>Binomial experiments. Binomial random variables. Computing binomial probabilities with R. Mean and variance of a binomial random variable.
	<dd><b>Sections: </b>3.5
	<dd><a href="MA-220-SP20/lesson-plans/11/learning-objectives.html">Learning Objectives</a>
	<dd><a href="MA-220-SP20/lesson-plans/11/homework.html">Homework 10</a>

<dt>March 2, Lecture 12:
	<dd><b>Topics: </b>Continuous random variables. The probability density function \(f\). The cumulative distribution function \(F\). Expectation and variance for continuous random variables.
	<dd><b>Sections: </b>4.1, 4.2
	<dd><a href="MA-220-SP20/lesson-plans/12/learning-objectives.html">Learning Objectives</a>
	<dd><a href="MA-220-SP20/lesson-plans/12/homework.html">Homework 11</a>
	<dd><a href ="https://ddarmon.shinyapps.io/dens-hist-to-dens-func/">Demo of Density Functions as Limits of Density Histograms</a>
	<dd><a href ="https://ddarmon.shinyapps.io/cdf-pdf-demo/">Demo of the Relationship Between the PDF and CDF of a Random Variable</a>

<dt>March 4, Lecture 13:
	<dd><b>Topics: </b>Standard Gaussian (normal) random variables. Non-standard Gaussian (normal) random variables. Why oh why couldn't the Gaussian cumulative distribution function be elementary? Computing Gaussian probabilities with R. Percentiles of Gaussian random variables.
	<dd><b>Sections: </b>4.3
	<dd><a href="MA-220-SP20/lesson-plans/13/learning-objectives.html">Learning Objectives</a>
	<dd><a href="MA-220-SP20/lesson-plans/13/homework.html">Homework 12</a>
	<dd><a href = "https://ddarmon.shinyapps.io/normal-area-demo/">Demo for Computing Normal Probability Queries Using R</a>
	<dd><a href = "https://ddarmon.shinyapps.io/normal-probability-queries-practice/">Practice with Computing Normal Probability Queries Using R</a>

<dt>March 9, Lecture 14:
	<dd><b>Topics: </b>Statistics and their sampling distributions. The sample mean. The central limit theorem.
	<dd><b>Sections: </b>6.1, 6.2
	<dd><a href="MA-220-SP20/lesson-plans/14/learning-objectives.html">Learning Objectives</a>
	<dd><a href="MA-220-SP20/lesson-plans/14/homework.html">Homework 13</a>
	<dd><a href="https://ddarmon.shinyapps.io/sampling-dist-enumerate/">Demo of the Sampling Distribution of a Statistic via Enumeration</a>
	<dd><a href="https://ddarmon.shinyapps.io/SamplingDistributionSimulation/">Demo of the Sampling Distribution of a Statistic via Simulation</a>

<dt>March 11, Lecture 15:
	<dd><b>Topics: </b>Point estimators. Example point estimators. Desirable properties of point estimators. The standard error of a point estimator.
	<dd><b>Sections: </b>7.1
	<dd><a href="MA-220-SP20/lesson-plans/15/learning-objectives.html">Learning Objectives</a>
	<dd><a href="MA-220-SP20/lesson-plans/15/homework.html">Homework 14</a>. <b>Due March 23.</b>
	<dd><a href="https://ddarmon.shinyapps.io/inferential-stats-demo/">Demo Motivating Inferential Statistics</a>

<dt>March 23, Lecture 16:
	<dd><b>Topics: </b>Margin of error for the sample mean. Interval estimators. Confidence intervals. Confidence interval for a population mean: population standard deviation known and unknown.
	<dd><b>Sections: </b>8.1, 8.3

<dt>March 25, Lecture 17:
	<dd><b>Topics: </b>Two-sided and one-sided confidence intervals for a population mean. Interpreting confidence intervals. Confidence interval for a population proportion.
	<dd><b>Sections: </b>8.1, 8.2

<dt>March 30, Lecture 18:
	<dd><b>Topics: </b>Hypothesis tests. Stating a claim about a population. Jargon of hypothesis testing: null and alternative hypotheses. Determining the null and alternive hypotheses based on a stated claim. Performing a hypothesis test using a confidence interval. Two-sided hypothesis tests for population means and proportions. One-sided hypothesis tests using one-sided confidence intervals.
	<dd><b>Sections: </b>9.1, 9.2, 9.3

<dt>April 1, Lecture 19:
	<dd><b>Topics: </b>Exam 2.
	<dd><b>Sections: </b>Chapters 3, 4, 6, 7, 8

<dt>April 6, Lecture 20:
	<dd><b>Topics: </b>Hypothesis tests. Types of errors in hypothesis testing. The logic of hypothesis tests. Test statistics for hypothesis tests. Using test statistics to test one-sided and two-sided alternative hypotheses.
	<dd><b>Sections: </b>9.1, 9.2, 9.3

<dt>April 8, Lecture 21:
	<dd><b>Topics: </b>Power of a hypothesis test. \(P\)-values. More practice with hypothesis tests.
	<dd><b>Sections: </b>9.1, 9.2, 9.4

<dt>April 13, Lecture 22:
	<dd><b>Topics: </b>Inferences about two populations. Inferences with independent samples. Inferences involving two population means.
	<dd><b>Sections: </b>10.1, 10.2

<dt>April 15, Lecture 23:
	<dd><b>Topics: </b>Inferences about two populations. Inferences involving two population proportions. Power.
	<dd><b>Sections: </b>10.4

<dt>April 20, Lecture 24:
	<dd><b>Topics: </b>Association between two quantitative variables. Scatterplots. Correlation vs. causation. Population and sample Pearson correlations. Confidence intervals and hypothesis tests for a population correlation.
	<dd><b>Sections: </b>12.5

<dt>April 22, Lecture 25:
	<dd><b>Topics: </b>Simple linear regression. Trendlines and interpreting the slope and intercept. Evaluating a regression model: standard error of prediction and median absolute error of prediction.
	<dd><b>Sections: </b>12.1, 12.2

<dt>April 27, Lecture 26:
	<dd><b>Topics: </b>Simple linear regression. Whence and wherefore the 'line of best fit'?. Confidence intervals for regression parameters. Multiple linear regression.
	<dd><b>Sections: </b>12.1, 12.2, 12.3, 12.6

<dt>May 4, Final Exam:
	<dd><b>Time: </b>11:35 AM - 2:25 PM
	<dd><b>Location: </b> Howard Hall 307 (HH 307)

</dl>