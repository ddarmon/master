<script src='https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>
<title>MA 380-01 Probability Methods for Actuarial Science (Spring 2019)</title>

<a href="http://www.thirdorderscientist.org"><em>David Darmon</em></a>

<h1>MA 380-01, Probability Methods for Actuarial Science</h1>

<h2>Spring 2019</h2>


<center>
Section 01: Tuesday, 1:15 PM &mdash; 2:35 PM; Thursday, 11:40 AM &mdash; 1:00 PM, Howard Hall 205
</center>

<P>This course will cover the probability theory necessary to solve problems on the Society of Actuaries' (SOA's) Exam P, the first exam in the credentialing process for both the SOA and the Casualty Actuarial Society (CAS). This exam covers material from a first course in calculus-based probability theory. A (non-exhaustive) list of those topics are given in the <a href = "#topics">Topics, Notes, Readings section</a> below. The course will alternate between lectures on topics and informal problem solving sessions. The problem solving sessions will be run by you, the students, with my assistance. A special emphasis will be given to solving questions in the cleverest way possible, since the 'right' or 'long' way may take too long given the structure of Exam P. In addition to covering the probability theory included on Exam P, we will learn about the career paths available to actuaries, and have guest speakers discuss their experiences as actuaries.

<h4>Prerequisites</h4>

<P>MA 220

<h4>Professor</h4>

<table>
<tr><td>Dr. David Darmon</td> <td></td><td>ddarmon [at] monmouth.edu</td></tr>
<tr><td></td><td></td><td>Howard Hall 241</td></tr>
</table>

<div id="topics"><h2>Topics, Notes, Readings</h2></div>

<P>This is currently a <em>tentative</em> listing of topics, in order.


<dl>
	<dt><em>Introduction:</em> What is an actuary? What is actuarial science? The credentialing process for becoming an actuary. Exam P. Tips and tricks for life-long learning.
    <dt><em>Combinatorial Probability:</em> Finding the probability of an outcome by counting. Combinatorics. Permutations, combinations, multisets, and all of the other ways to assign \(n\) items to \(k\) slots. How combinatorics relates to sampling.
    <dt><em>Probability:</em> Probability as a measure on a set. Set operations: union, intersection, difference, and so on. Venn diagrams for reasoning about probabilities. Sample spaces and events. Assigning probabilities to events, in all the ways.
    <dt><em>Discrete random variables:</em> How to talk about discrete random variables: probability mass functions, cumulative distribution functions, expectations, and moment generating functions. Discrete random vectors as multidimensional generalizations of discrete random variables.
    <dt><em>Some parametric discrete distributions:</em> Uniform. Bernoulli. Descendants of Bernoulli: binomial, negative binomial, geometric. Like binomial, but without replacement: hypergeometric. Poisson.
    <dt><em>Continuous random variables:</em> How to talk about continuous random variables: probability density functions, cumulative distribution functions, expectations, and moment generating functions. Mixed-type random variables.
    <dt><em>Some parametric continuous distributions:</em> Exponential. Normal. Gamma. Beta. Connections between families of random variables. The Russian inequalities. The law of large numbers. The central limit theorem.
    <dt><em>Random vectors and multivariate distributions:</em> How to talk about random vectors:  joint probability mass / density functions, joint cumulative distribution functions, and joint moment generating functions. Expectations of random vectors. Conditional random variables and conditional distributions.
    <dt><em>More techniques in probability theory:</em> Transformations of random variables. Order statistics. More on the moment generating function. More on variances and covariances via linear algebra. More on conditioning arguments.
</dl>

See the end for the current lecture schedule, subject to revision.  Homework and additional resources will be linked there, as available.

<h2>Course Mechanics</h2>

<h4>Office Hours</h4>

<p>I will have office hours at the following four times each week:

<center><table>
    <tr><td>Monday, &nbsp;&nbsp;10:00&mdash;11:00 AM</td> <td>Howard Hall 241</td></tr>
</td></tr>
    <tr><td>Tuesday, &nbsp;&nbsp;03:00&mdash;04:00 PM</td> <td>Howard Hall 241</td></tr>
</td></tr>
    <tr><td>Thursday, 10:00&mdash;11:00 AM</td> <td>Howard Hall 241</td></tr>
</td></tr>
    <tr><td>Thursday, 01:30&mdash;02:30 PM</td> <td>Howard Hall 241</td></tr>
</table></center>

<p>I have an open-door policy during those times: you can show up unannounced. If you cannot make the scheduled office hours, please e-mail me about making an appointment.

<p>If you are struggling with the problem sets, having difficulty with any concepts, or just want to chat, please visit me during my office hours. I am here to help.

<h4>Grading Policy</h4> 

Your final grade will be determined by the following weighting scheme:

<dl>
	<dd> 50% for in-class presentation of problem solutions
	<dd> 20% for investigation into and reflection on actuarial science
	<dd> 15% for inter-class skills work
	<dd> 15% for inter-class review
</dl>

I will use the standard 10-point breakdown to assign letter grades to numerical grades:
<ul>
	<li> \([90, 100] \to \text{A}\)
	<li> \([80, 90) \,\,\, \to \text{B}\)
	<li> \([70, 80) \,\,\, \to \text{C}\)
	<li> \([60, 70) \,\,\, \to \text{D}\)
	<li> \([0, 60) \,\,\,\,\,\, \to \text{F}\)
</ul>

<h4>In-class Presentation of Problem Solutions</h4>

<p>During the informal problem solving sessions, you will spend the first 30 minutes working individually on a collection of problems related to material we have covered in the class to-date. I will then select three students (randomly and without replacement) to act as problem solving guides for that session. For the next 40 minutes, the selected students will alternate leading a class discussion on how to solve a problem of their choice from the collection of problems. These discussions are meant to be interactive amongst <strong>all</strong> students, with the <strong>main presentation</strong> coming from the current lead student.
	
<h4>Investigation into and Reflection on Actuarial Science</h4>

We will have occasional guests visit to discuss their experience working as an actuary, provide advice about preparing for a career as an actuary, and present on other topics related to actuarial science. After these discussions, I will provide a writing prompt for you to reflect on what you learned from the guest and how it has impacted your views of actuarial science and the actuarial profession. I will provide a rubric for these reflections as they are assigned.

<h4>Inter-class Skills Work</h4>

<p>Problem sets will be assigned at the end of every Thursday meeting, and listed in the <a href="#schedule">Schedule</a> section of this page. Problems sets are due at the beginning of the next class meeting. Problem sets will consist of <strong>required</strong> problems, as well as <strong>suggested</strong> problems.
	
<p><strong>Note:</strong> The solutions to each exercise in our textbook are listed in the back of the book, so you should be sure to write up how you arrived at an answer, not just the answer you arrived at. Do, however, use the provided answers to check your solutions.

<h4>Inter-class Review</h4>

<p>One of the most important skills needed to master mathematics is memory. To do mathematics, you need to make connections between concepts stored in your long-term memory, and before you can do that, you need to store those memories in the first place. One of the best methods for strengthening long-term memory is <strong>retrieval practice</strong> (think flash cards) combined with <strong>spaced repetition</strong> (think reviewing flash cards on an intelligent schedule). This is the exact opposite of how many students study, which typically takes the form of browsing notes (and thus skipping over retrieving the information from their own memories) immediately before the information is needed (i.e. 'cramming'). Unfortunately, this is one of the worst ways to commit information to long-term memory, despite the fact that cramming <em>feels</em> effective in the short-term. Retrieval practice with spaced repetition is more effective than the browse-and-cram approach, takes less time, and is more enjoyable!

<p>All of this is true, but even more so, in preparing for the SOA's Exam P. To solve the 30 questions on Exam P within the allotted 3 hours, you need to have a great deal of information at-the-ready: <em>e.g.</em> How is the sum of \(n\) iid Poisson random variables with rate parameters \(\lambda\) distributed? How do I get moments from a moment generating function? What is the Darth Vader rule for quickly evaluating the mean of random variable with non-negative support? Etc. Many of these shortcuts you can pick up, in the short term, by working problems. But for long-term retention, spaced retrieval practice will be both more efficient (less total time) and more effective (longer and stronger retention).

<p>As part of inter-class review, you are required to regularly use Anki, and submit your Anki decks via eCampus. See <a href = "#anki">below</a> for details on Anki.

<p>I will start out by providing you with Anki decks, but we will transition to you generating your own Anki decks. This will make the decks more personalized and more meaningful. In the process, you will (re-)learn how to typeset math using <a href = "https://en.wikipedia.org/wiki/LaTeX">LaTeX</a>.

<p>See <a href = "MA-380-SP19/additional-syllabus-pages/preclass-prep-instructions.html">here</a> for the instructions on submitting your Anki decks via eCampus.

<h4>Attendance</h4>

Required. If you expect to miss 2-3 sessions of the course, you should take the course during another semester.

<h4>Textbook</h4>

<P>The <strong>required</strong> textbook is:
<ul>
<li> Leonard A. Asimow and Mark M. Maxwell, <em>Probability & Statistics with Applications: A Problem Solving Text</em>, 2nd Edition (ACTEX Academic Series, 2015, ISBN: 9781625424723). <a href = "http://mubookstore.monmouth.edu/TextBookDetail.aspx?BookPriceID=7939676&MBSNumber=1846066&SecID=9880720&trm=SPRING%2019#.XC5bVC2ZNhE">Link to University Store</a>
</ul>

<!-- <h4>Collaboration, Cheating, and Plagiarism</h4>

All submitted work should be your own. You are welcome and encouraged to consult with others while working on an assignment, including other students in the class and tutors in the <a href="https://www.monmouth.edu/department-mathematics/math-learning-center/">Mathematics Learning Center</a>.  However, whenever you have had assistance with a problem, you must state so at the beginning of the problem solution.  Unless this mechanism is abused, there will be no reduction in credit for using and reporting such assistance.  This policy applies to both individual and group work. In group work, you only need to acknowledge help from outside the group. This policy does <b>not</b> apply to examinations.

<h4>Statement on Special Accommodations</h4>

Students with disabilities who need special accommodations for this class are encouraged to meet with me or the appropriate disability service provider on campus as soon as possible.  In order to receive accommodations, students must be registered with the appropriate disability service provider on campus as set forth in the student handbook and must follow the University procedure for self-disclosure, which is stated in the University <em>Guide to Services and Accommodations for Students with Disabilities</em>.  Students will not be afforded any special accommodations for academic work completed prior to the disclosure of the disability, nor will they be afforded any special accommodations prior to the completion of the documentation process with the appropriate disability office. -->

<div id="anki"><h2>Anki</h2></div>

<P> We will use <a href = "https://ankiweb.net/about">Anki</a> for spaced retrieval practice throughout the semester. Anki is open-source, free (as in both <a href = "https://en.wikipedia.org/wiki/Gratis_versus_libre"><em>gratis</em> and <em>libre</em></a>) software. You can download Anki to your personal computer from <a href = "https://apps.ankiweb.net/#download">this link</a>. If you have ever used flashcards, then Anki should be fairly intuitive. If you would like more details you can find Anki's User Manual <a href = "https://apps.ankiweb.net/docs/manual.html">here</a>.

<P> <strong>Note:</strong> Anki has both desktop and mobile phone variants. Please use the desktop variant.

<div id="schedule"><h2>Schedule</h2></div>

<strong>Subject to revision</strong>.  Assignments and solutions will all be linked here, as they are available.  All readings are from the textbook by Asimow and Maxwell unless otherwise noted.

<dl>

<dt>Prior to January 22, Lecture 0:
		<dd><b>Topics: </b>Spaced retrieval practice. Pre-class reflection.
		<dd><a href="MA-380-SP19/lesson-plans/0/homework.html">Pre-class Assignments</a>
<dt>January 22, Lecture 1:
	<dd><b>Topics: </b>Introduction to class. Introduction to the Society of Actuaries' Exam P. "Pre-treatment" Exam. Study Hacks.
	<dd><b>Sections: </b>NA
<dt>January 24, Lecture 2:
	<dd><b>Topics: </b>General rules of probability. Sets, sample spaces, and events. Correspondence between set operations and Venn diagrams. \( P(A \cap B) \). \( P(A \cup B) \). Conditional probability and statistical independence. Repeated factoring of probabilities. The law of total probability. Bayes's theorem.
	<dd><b>Sections: </b>Chapter 2
		<dd><a href="MA-380-SP19/lesson-plans/2/learning-objectives.html">Learning Objectives</a>
		<dd><a href="MA-380-SP19/lesson-plans/2/homework.html">Homework 1</a>
			
<dt>January 29, Lecture 3:
	<dd><b>Topics: </b>General rules of probability. Problem solving session.
	<dd><b>Sections: </b>[Chapter 2]
<dt>January 31, Lecture 4:
	<dd><b>Topics: </b>Discrete random variables. The probability mass function. The cumulative distribution function. Expectation of functions of discrete random variables. Summaries of central tendency. Summaries of dispersion.
	<dd><b>Sections: </b>Chapter 3
		<dd><a href="MA-380-SP19/lesson-plans/4/learning-objectives.html">Learning Objectives</a>
		<dd><a href="MA-380-SP19/lesson-plans/4/homework.html">Homework 2</a>

<dt>February 5, Lecture 5:
	<dd><b>Topics: </b>Discrete random variables. Problem solving session.
	<dd><b>Sections: </b>[Chapter 2, Chapter 3]

<dt>February 7, Lecture 6:
	<dd><b>Topics: </b>Discrete random variables. Conditional expectations and variances. Review of sequences, partial sums, series, and power series expansions.
	<dd><b>Sections: </b>Chapter 3
		<dd><a href="MA-380-SP19/lesson-plans/6/learning-objectives.html">Learning Objectives</a>
		<dd><a href="MA-380-SP19/lesson-plans/6/homework.html">Homework 3</a>

<dt>February 12, Lecture 7:
	<dd><b>Topics: </b>Some parametric discrete distributions. Uniform. Bernoulli. Descendants of Bernoulli: binomial.
	<dd><b>Sections: </b>Chapter 4
		<dd><a href="MA-380-SP19/lesson-plans/7/learning-objectives.html">Learning Objectives</a>
		<dd><a href="MA-380-SP19/lesson-plans/7/homework.html">Investigation into and Reflection on Actuarial Science 1</a>

<dt>February 14, Lecture 8:
	<dd><b>Topics: </b>Some (more) parametric discrete distributions. Descendants of Bernoulli: negative binomial, geometric.
	<dd><b>Sections: </b>Chapter 4
		<dd><a href="MA-380-SP19/lesson-plans/8/learning-objectives.html">Learning Objectives</a>
		<dd><a href="MA-380-SP19/lesson-plans/8/homework.html">Homework 4</a>

<dt>February 19, Lecture 9:
	<dd><b>Topics: </b>Some parametric discrete distributions. Problem solving session.
	<dd><b>Sections: </b>[Chapter 2, Chapter 4]

<dt>February 21, Lecture 10:
	<dd><b>Topics: </b>Some (more) parametric discrete distributions. Like Binomial, but without replacement: hypergeometric. Poisson. Continuous random variables. The probability density function. The cumulative probability function.
	<dd><b>Sections: </b>Chapters 4 and 5
		<dd><a href="MA-380-SP19/lesson-plans/10/learning-objectives.html">Learning Objectives</a>
		<dd><a href="MA-380-SP19/lesson-plans/10/homework.html">Homework 5</a>

<dt>February 26, Lecture 11:
	<dd><b>Topics: </b>Continuous random variables. Expectations of functions of continuous random variables. Mixed-type random variables.
	<dd><b>Sections: </b>Chapter 5
		<dd><a href="MA-380-SP19/lesson-plans/11/learning-objectives.html">Learning Objectives</a>

<dt>February 28, Lecture 12:
	<dd><b>Topics: </b>Continuous random variables. Applications to insurance. Moment generating functions.
	<dd><b>Sections: </b>Chapter 5
		<dd><a href="MA-380-SP19/lesson-plans/12/learning-objectives.html">Learning Objectives</a>
		<dd><a href="MA-380-SP19/lesson-plans/12/homework.html">Homework 6</a>

<dt>March 5, Lecture 13:
	<dd><b>Topics: </b>Continuous random variables. Problem solving session.
	<dd><b>Sections: </b>[Chapter 2, Chapter 5]

<dt>March 7, Lecture 14:
	<dd><b>Topics: </b>Some parametric continuous distributions. Uniform. Exponential.
	<dd><b>Sections: </b>Chapter 6
		<dd><a href="MA-380-SP19/lesson-plans/14/learning-objectives.html">Learning Objectives</a>
		<dd><a href="MA-380-SP19/lesson-plans/14/homework.html">Homework 7</a>
		<dd><a href = "http://ramanujan.math.trinity.edu/rdaileda/teach/s18/m3357/parts.pdf">Reference on the Tabular Method for Integration by Parts</a>

<dt>March 12, Lecture 15:
	<dd><b>Topics: </b>Guest Speaker.
	<dd><b>Sections: </b>None

<dt>March 14, Lecture 16:
	<dd><b>Topics: </b>Some (more) parametric continuous distributions. Gamma. Normal. Log-normal. Chi-squared. The central limit theorem. Application of CLT to approximating the CDF of a binomial random variable using the CDF of a normal random variable.
	<dd><b>Sections: </b>Chapter 6
		<dd><a href="MA-380-SP19/lesson-plans/16/learning-objectives.html">Learning Objectives</a>
		<dd><a href = "https://ddarmon.shinyapps.io/normal-approximation-to-binomial-demo/">Shiny Demo for Continuity Correction</a>

<dt>March 26, Lecture 17:
	<dd><b>Topics: </b>Review of multidimensional integration. Random vectors and multivariate distributions. The joint probability mass / density function. The joint cumulative distribution function.
	<dd><b>Sections: </b>Chapter 7

<dt>March 28, Lecture 18:
	<dd><b>Topics: </b>Random vectors and multivariate distributions. Independence and factoring of joint probability functions. Conditional random variables and conditional distributions.
	<dd><b>Sections: </b>Chapter 7

<dt>April 2, Lecture 19:
	<dd><b>Topics: </b>Linear dependence: correlation and covariance. Using linear algebra to evaluate variances and covariances. Special cases: the multinomial and multivariate normal distributions. Moment generating functions for random vectors.
	<dd><b>Sections: </b>Chapter 7

<dt>April 4, Lecture 20:
	<dd><b>Topics: </b>Random vectors and multivariate distributions. Problem solving session.
	<dd><b>Sections: </b>[Chapter 2, Chapter 7]

<dt>April 9, Lecture 21:
	<dd><b>Topics: </b>More techniques in probability theory. Transformations of random variables. Order statistics. More on the moment generating function. More on variances and covariances via linear algebra. More on conditioning arguments.
	<dd><b>Sections: </b>Chapter 8

<dt>April 11, Lecture 22:
	<dd><b>Topics: </b>More techniques in probability theory. Problem solving session.
	<dd><b>Sections: </b>[Chapter 2, Chapter 8]
</dl>